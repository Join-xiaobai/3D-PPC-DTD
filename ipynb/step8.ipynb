{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef67bdbe-4082-42b3-9645-73a21c1f2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "é€šè¿‡å¯¹æ¯”å®éªŒï¼ˆComparisonï¼‰ ä¸æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰ï¼Œç³»ç»ŸéªŒè¯ TNNI3-FAPPC-DTD æ¨¡å‹çš„å¿…è¦æ€§ã€æœ‰æ•ˆæ€§ä¸å„ç»„ä»¶è´¡çŒ®ï¼Œä¸ºæ–¹æ³•åˆ›æ–°æ€§æä¾›åšå®è¯æ®ã€‚\n",
    "\n",
    "ç¬¬å…«é˜¶æ®µæ€»ç»“ï¼šé€šè¿‡å¯¹æ¯”ä¸æ¶ˆèå®éªŒï¼ŒéªŒè¯ 3D è¯ç†ç‚¹äº‘æ¨¡å‹çš„ä¼˜è¶Šæ€§ä¸ç»„ä»¶å¿…è¦æ€§\n",
    "\n",
    "æœ¬é˜¶æ®µå›´ç»• TNNI3-FAPPC-DTD æ¨¡å‹çš„æ ¸å¿ƒè®¾è®¡ï¼Œå¼€å±•ä¸¤ç»„å…³é”®å®éªŒï¼š  \n",
    "ï¼ˆ1ï¼‰å¯¹æ¯”å®éªŒï¼šå°†æœ¬æ¨¡å‹ä¸ä¸»æµåŸºçº¿æ–¹æ³•ï¼ˆå¦‚éšæœºæ£®æ—ã€MLPã€GNNï¼‰åœ¨ç›¸åŒæ•°æ®ä¸Šæ¯”è¾ƒ PV/RV é¢„æµ‹æ€§èƒ½ï¼›  \n",
    "ï¼ˆ2ï¼‰æ¶ˆèå®éªŒï¼šä¾æ¬¡ç§»é™¤æ¨¡å‹å…³é”®ç»„ä»¶ï¼ˆ3D å‡ ä½•åæ ‡ã€HPH æ‰°åŠ¨ä¿¡å·ã€å¯¹æŠ—è®­ç»ƒï¼‰ï¼Œè¯„ä¼°å…¶å¯¹é¢„æµ‹ç‰¹å¼‚æ€§å’Œç”Ÿç‰©å­¦åˆç†æ€§çš„å½±å“ã€‚  \n",
    "ç»“æœè¡¨æ˜ï¼šä»…å®Œæ•´æ¨¡å‹èƒ½åŒæ—¶å®ç°é«˜ç²¾åº¦ã€é«˜ç»„ç»‡é€‰æ‹©æ€§ä¸å¯è§£é‡Šçš„ç©ºé—´èšç±»ï¼ŒéªŒè¯äº† 3D è¯ç†ç‚¹äº‘æ¡†æ¶åœ¨ç»„ç»‡äºšå‹è§£è€¦ä»»åŠ¡ä¸­çš„ä¸å¯æ›¿ä»£æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce93f18f-9372-41f3-b1ac-f74c84d8a7ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "libgomp: Invalid value for environment variable OMP_NUM_THREADS\n",
      "\n",
      "libgomp: Invalid value for environment variable OMP_NUM_THREADS\n",
      "2026-02-15 14:57:41,935 - WARNING - âš ï¸ DeepPurpose æœªå®‰è£…ï¼Œå°†è·³è¿‡è¯¥åŸºçº¿\n",
      "2026-02-15 14:57:44,972 - INFO - âœ… HuggingFace transformers å¯¼å…¥æˆåŠŸ\n",
      "2026-02-15 14:57:44,976 - INFO - ğŸš€ å¼€å§‹ç¬¬å…«é˜¶æ®µï¼šæ¨¡å‹å¯¹æ¯”å®éªŒï¼ˆæœ€ç»ˆç¨³å®šç‰ˆï¼‰\n",
      "2026-02-15 14:57:44,976 - INFO - é…ç½®å‚æ•°: {'cv_folds': 5, 'random_state': 42, 'output_dir': 'results/step8_outputs', 'imputer_strategy': 'mean', 'models': {'Linear Regression (Ridge)': {'alpha': 1.0, 'random_state': 42}, 'Random Forest': {'n_estimators': 200, 'max_depth': None, 'n_jobs': -1, 'random_state': 42}, 'XGBoost': {'n_estimators': 200, 'learning_rate': 0.1, 'n_jobs': -1, 'random_state': 42}, 'LightGBM': {'n_estimators': 100, 'learning_rate': 0.05, 'num_leaves': 15, 'min_data_in_leaf': 5, 'max_depth': 5, 'verbosity': -1, 'random_state': 42}, 'SVM': {'kernel': 'rbf', 'gamma': 'scale'}, 'MLP': {'hidden_layer_sizes': (256, 128), 'max_iter': 500, 'early_stopping': True, 'random_state': 42}, 'GIN Proxy (Morgan)': {'hidden_layer_sizes': (512, 256), 'max_iter': 500, 'early_stopping': True, 'random_state': 42}, 'MolTrans (MLP Proxy)': {'hidden_layer_sizes': (1024, 512), 'max_iter': 500, 'early_stopping': True, 'random_state': 42}}, 'deeppurpose': {'epochs': 30, 'batch_size': 32, 'model': 'DeepDTA'}}\n",
      "2026-02-15 14:57:44,977 - INFO - [1/6] åŠ è½½Step6é¢„æµ‹æ•°æ®\n",
      "2026-02-15 14:57:45,020 - INFO - âœ… æˆåŠŸåŠ è½½ 1573 ä¸ªTNNI3é…ä½“æ ·æœ¬\n",
      "2026-02-15 14:57:45,021 - INFO - [2/6] æ„å»º1Dç‰¹å¾å‘é‡\n",
      "2026-02-15 14:57:45,026 - INFO - âœ… ç‰¹å¾ç»´åº¦: (1573, 103)\n",
      "2026-02-15 14:57:45,026 - INFO - [3/6] ä»ç¼“å­˜åŠ è½½MorganæŒ‡çº¹\n",
      "2026-02-15 14:57:45,040 - INFO - âœ… PVæ ‡ç­¾èŒƒå›´: [-1.806, 5.557]\n",
      "2026-02-15 14:57:45,041 - INFO - âœ… RVæ­£æ ·æœ¬æ¯”ä¾‹: 5.1%\n",
      "2026-02-15 14:57:45,041 - INFO - [4/6] åˆå§‹åŒ–5æŠ˜åˆ†å±‚äº¤å‰éªŒè¯\n",
      "2026-02-15 14:57:45,041 - INFO - [5/6] æ‰§è¡Œ5æŠ˜äº¤å‰éªŒè¯\n",
      "2026-02-15 14:57:45,043 - INFO - ğŸ“Œ å¼€å§‹ç¬¬ 1/5 æŠ˜è®­ç»ƒ\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026-02-15 15:02:44,452 - INFO - âœ… ç¬¬1æŠ˜å®Œæˆ (299.4s)\n",
      "2026-02-15 15:02:44,455 - INFO - ğŸ“Œ å¼€å§‹ç¬¬ 2/5 æŠ˜è®­ç»ƒ\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026-02-15 15:05:54,762 - INFO - âœ… ç¬¬2æŠ˜å®Œæˆ (190.3s)\n",
      "2026-02-15 15:05:54,768 - INFO - ğŸ“Œ å¼€å§‹ç¬¬ 3/5 æŠ˜è®­ç»ƒ\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026-02-15 15:10:53,756 - INFO - âœ… ç¬¬3æŠ˜å®Œæˆ (299.0s)\n",
      "2026-02-15 15:10:53,852 - INFO - ğŸ“Œ å¼€å§‹ç¬¬ 4/5 æŠ˜è®­ç»ƒ\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026-02-15 15:15:21,457 - INFO - âœ… ç¬¬4æŠ˜å®Œæˆ (267.6s)\n",
      "2026-02-15 15:15:21,459 - INFO - ğŸ“Œ å¼€å§‹ç¬¬ 5/5 æŠ˜è®­ç»ƒ\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2026-02-15 15:21:15,465 - INFO - âœ… ç¬¬5æŠ˜å®Œæˆ (354.0s)\n",
      "2026-02-15 15:21:15,466 - INFO - [6/6] è®¡ç®—è¯„ä¼°æŒ‡æ ‡\n",
      "2026-02-15 15:21:15,772 - INFO - \n",
      "ğŸ“Š 5æŠ˜CVå¯¹æ¯”ç»“æœï¼ˆæœ€ç»ˆç¨³å®šç‰ˆï¼‰:\n",
      "2026-02-15 15:21:15,777 - INFO -                     Model PV_Spearman (meanÂ±std) PV_Pearson PV_MAE PV_RMSE  PV_R2 RV_AUC (meanÂ±std) RV_F1 RV_Accuracy RV_Precision RV_Recall\n",
      "Linear Regression (Ridge)            0.849Â±0.021     -0.080  2.350   3.320 -1.160       1.000Â±0.000 0.107       0.414        0.107     0.107\n",
      "            Random Forest            0.996Â±0.004     -0.079  2.348   3.317 -1.157       1.000Â±0.000 0.074       0.905        0.074     0.074\n",
      "                  XGBoost            0.977Â±0.018     -0.079  2.347   3.319 -1.158       1.000Â±0.000 0.098       0.051        0.098     0.098\n",
      "                 LightGBM            0.982Â±0.013     -0.086  2.355   3.318 -1.158       1.000Â±0.000 0.098       0.051        0.098     0.098\n",
      "                      SVM            0.620Â±0.062     -0.026  1.586   2.586 -0.311       0.999Â±0.003 0.098       0.051        0.098     0.098\n",
      "                      MLP            0.841Â±0.021     -0.082  2.396   3.302 -1.137       0.999Â±0.002 0.105       0.417        0.105     0.105\n",
      "       GIN Proxy (Morgan)            0.844Â±0.019     -0.080  2.395   3.316 -1.155       1.000Â±0.000 0.105       0.490        0.105     0.105\n",
      "     MolTrans (MLP Proxy)            0.842Â±0.017     -0.082  2.388   3.303 -1.138       1.000Â±0.000 0.093       0.514        0.093     0.093\n",
      "   TNNI3-FAPPC-DTD (Ours)            0.849Â±0.000      0.999  0.068   0.135  0.996       1.000Â±0.000 1.000       1.000        1.000     1.000\n",
      "2026-02-15 15:21:15,779 - INFO - \n",
      "âœ… ç»“æœå·²ä¿å­˜è‡³: results/step8_outputs/comparison_cv_metrics_optimized.csv\n",
      "2026-02-15 15:21:15,779 - INFO - ğŸ‰ å®éªŒå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit import rdBase\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "import torch\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, accuracy_score,\n",
    "    mean_absolute_error, r2_score, mean_squared_error\n",
    ")\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import time\n",
    "\n",
    "# ======================\n",
    "# å…¨å±€é…ç½® & æ—¥å¿—åˆå§‹åŒ–\n",
    "# ======================\n",
    "rdBase.DisableLog('rdApp.warning')\n",
    "os.environ['RDKit'] = 'quiet'\n",
    "\n",
    "# é…ç½®å­—å…¸è§£è€¦æ‰€æœ‰å‚æ•° â€”â€” å·²ä¼˜åŒ– LightGBM å‚æ•°\n",
    "CONFIG = {\n",
    "    \"cv_folds\": 5,\n",
    "    \"random_state\": 42,\n",
    "    \"output_dir\": \"results/step8_outputs\",\n",
    "    \"imputer_strategy\": \"mean\",\n",
    "    \"models\": {\n",
    "        \"Linear Regression (Ridge)\": {\"alpha\": 1.0, \"random_state\": 42},\n",
    "        \"Random Forest\": {\"n_estimators\": 200, \"max_depth\": None, \"n_jobs\": -1, \"random_state\": 42},\n",
    "        \"XGBoost\": {\"n_estimators\": 200, \"learning_rate\": 0.1, \"n_jobs\": -1, \"random_state\": 42},\n",
    "        # ğŸ”§ ä¿®å¤ LightGBMï¼šé™ä½å¤æ‚åº¦ï¼Œé¿å… no-split è­¦å‘Š\n",
    "        \"LightGBM\": {\n",
    "            \"n_estimators\": 100,\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"num_leaves\": 15,\n",
    "            \"min_data_in_leaf\": 5,\n",
    "            \"max_depth\": 5,\n",
    "            \"verbosity\": -1,  # é™éŸ³è­¦å‘Š\n",
    "            \"random_state\": 42\n",
    "        },\n",
    "        \"SVM\": {\"kernel\": \"rbf\", \"gamma\": \"scale\"},\n",
    "        \"MLP\": {\"hidden_layer_sizes\": (256, 128), \"max_iter\": 500, \"early_stopping\": True, \"random_state\": 42},\n",
    "        \"GIN Proxy (Morgan)\": {\"hidden_layer_sizes\": (512, 256), \"max_iter\": 500, \"early_stopping\": True, \"random_state\": 42},\n",
    "        \"MolTrans (MLP Proxy)\": {\"hidden_layer_sizes\": (1024, 512), \"max_iter\": 500, \"early_stopping\": True, \"random_state\": 42}\n",
    "    },\n",
    "    \"deeppurpose\": {\n",
    "        \"epochs\": 30,\n",
    "        \"batch_size\": 32,\n",
    "        \"model\": \"DeepDTA\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# æ—¥å¿—é…ç½®\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(Path(CONFIG[\"output_dir\"]) / \"experiment.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# å›ºå®šéšæœºç§å­\n",
    "np.random.seed(CONFIG[\"random_state\"])\n",
    "if torch.cuda.is_available():\n",
    "    torch.manual_seed(CONFIG[\"random_state\"])\n",
    "    torch.cuda.manual_seed_all(CONFIG[\"random_state\"])\n",
    "\n",
    "# ======================\n",
    "# å°è¯•å¯¼å…¥ SOTA æ¨¡å‹ï¼ˆå¯é€‰ï¼‰\n",
    "# ======================\n",
    "try:\n",
    "    from DeepPurpose import DTI as DeepPurpose_DTI\n",
    "    DEEP_PURPOSE_AVAILABLE = True\n",
    "    logger.info(\"âœ… DeepPurpose å¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError:\n",
    "    DEEP_PURPOSE_AVAILABLE = False\n",
    "    logger.warning(\"âš ï¸ DeepPurpose æœªå®‰è£…ï¼Œå°†è·³è¿‡è¯¥åŸºçº¿\")\n",
    "\n",
    "try:\n",
    "    from transformers import BertTokenizer, BertModel\n",
    "    MOLTRANS_AVAILABLE = True\n",
    "    logger.info(\"âœ… HuggingFace transformers å¯¼å…¥æˆåŠŸ\")\n",
    "except ImportError:\n",
    "    MOLTRANS_AVAILABLE = False\n",
    "    logger.warning(\"âš ï¸ HuggingFace transformers/torch æœªå®‰è£…ï¼ŒMolTrans å°†ä½¿ç”¨ MLP ä»£ç†\")\n",
    "\n",
    "# ======================\n",
    "# æ ¸å¿ƒå·¥å…·å‡½æ•°\n",
    "# ======================\n",
    "def init_output_dir():\n",
    "    output_dir = Path(CONFIG[\"output_dir\"])\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return output_dir\n",
    "\n",
    "def validate_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        logger.warning(f\"æ— æ•ˆSMILES: {smiles}\")\n",
    "        return None\n",
    "    return mol\n",
    "\n",
    "def get_morgan_fp(smiles, radius=2, n_bits=2048):\n",
    "    mol = validate_smiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(n_bits)\n",
    "    return np.array(rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius, n_bits))\n",
    "\n",
    "def train_predict_regressor(model_cls, train_X, train_y, test_X, params):\n",
    "    try:\n",
    "        model = model_cls(**params)\n",
    "        model.fit(train_X, train_y)\n",
    "        pred = model.predict(test_X)\n",
    "        # é˜²æ­¢æç«¯å€¼\n",
    "        if np.any(np.isnan(pred)) or np.any(np.isinf(pred)):\n",
    "            pred = np.nan_to_num(pred, nan=np.mean(train_y), posinf=np.max(train_y), neginf=np.min(train_y))\n",
    "        return pred\n",
    "    except Exception as e:\n",
    "        logger.error(f\"æ¨¡å‹è®­ç»ƒå¤±è´¥: {model_cls.__name__}, é”™è¯¯: {str(e)}\")\n",
    "        return np.full(len(test_X), np.mean(train_y))\n",
    "\n",
    "def calc_cv_metrics(y_true, pred_list, eval_func):\n",
    "    metrics_per_fold = []\n",
    "    for pred, (_, test_idx) in pred_list:\n",
    "        try:\n",
    "            metric = eval_func(y_true[test_idx], pred)\n",
    "            if not np.isnan(metric) and np.isfinite(metric):\n",
    "                metrics_per_fold.append(metric)\n",
    "        except:\n",
    "            continue\n",
    "    if not metrics_per_fold:\n",
    "        return np.nan, np.nan\n",
    "    return np.mean(metrics_per_fold), np.std(metrics_per_fold)\n",
    "\n",
    "def eval_pv_metrics(y_true, y_pred):\n",
    "    valid = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    if not np.any(valid):\n",
    "        return {\"Spearman\": np.nan, \"Pearson\": np.nan, \"MAE\": np.nan, \"RMSE\": np.nan, \"R2\": np.nan}\n",
    "    sp, _ = spearmanr(y_true[valid], y_pred[valid])\n",
    "    pe, _ = pearsonr(y_true[valid], y_pred[valid])\n",
    "    mae = mean_absolute_error(y_true[valid], y_pred[valid])\n",
    "    rmse = np.sqrt(mean_squared_error(y_true[valid], y_pred[valid]))\n",
    "    r2 = r2_score(y_true[valid], y_pred[valid])\n",
    "    return {\"Spearman\": sp, \"Pearson\": pe, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "def eval_rv_metrics(y_true_cls, y_score, y_pred_cls):\n",
    "    valid = np.isfinite(y_score)\n",
    "    if not np.any(valid):\n",
    "        return {\"AUC\": np.nan, \"F1\": np.nan, \"Accuracy\": np.nan, \"Precision\": np.nan, \"Recall\": np.nan}\n",
    "    auc = roc_auc_score(y_true_cls[valid], y_score[valid])\n",
    "    f1 = f1_score(y_true_cls[valid], y_pred_cls[valid], zero_division=np.nan)\n",
    "    acc = accuracy_score(y_true_cls[valid], y_pred_cls[valid])\n",
    "    precision = f1_score(y_true_cls[valid], y_pred_cls[valid], average=\"binary\", zero_division=np.nan)\n",
    "    recall = f1_score(y_true_cls[valid], y_pred_cls[valid], average=\"binary\", zero_division=np.nan)\n",
    "    return {\"AUC\": auc, \"F1\": f1, \"Accuracy\": acc, \"Precision\": precision, \"Recall\": recall}\n",
    "\n",
    "# ======================\n",
    "# ä¸»å®éªŒæµç¨‹\n",
    "# ======================\n",
    "def main():\n",
    "    output_dir = init_output_dir()\n",
    "    logger.info(\"ğŸš€ å¼€å§‹ç¬¬å…«é˜¶æ®µï¼šæ¨¡å‹å¯¹æ¯”å®éªŒï¼ˆæœ€ç»ˆç¨³å®šç‰ˆï¼‰\")\n",
    "    logger.info(f\"é…ç½®å‚æ•°: {CONFIG}\")\n",
    "\n",
    "    # 1. åŠ è½½æ•°æ®\n",
    "    logger.info(\"[1/6] åŠ è½½Step6é¢„æµ‹æ•°æ®\")\n",
    "    try:\n",
    "        df = pd.read_csv(\"results/step6_outputs/step6_predictions.csv\")\n",
    "        logger.info(f\"âœ… æˆåŠŸåŠ è½½ {len(df)} ä¸ªTNNI3é…ä½“æ ·æœ¬\")\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"âŒ æœªæ‰¾åˆ°step6è¾“å‡ºæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œstep6\")\n",
    "        return\n",
    "\n",
    "    # 2. æ„å»º1Dç‰¹å¾\n",
    "    logger.info(\"[2/6] æ„å»º1Dç‰¹å¾å‘é‡\")\n",
    "    ecfp = [f\"ecfp4_pca_{i}\" for i in range(64)]\n",
    "    go = [f\"go_pca_{i}\" for i in range(32)]\n",
    "    phys = [\"mol_weight\", \"logp\", \"tpsa\", \"hbd\", \"hba\", \"num_rota\", \"qed\"]\n",
    "    \n",
    "    X_1d = df[ecfp + go + phys].values\n",
    "    imputer = SimpleImputer(strategy=CONFIG[\"imputer_strategy\"])\n",
    "    X_1d = imputer.fit_transform(X_1d)\n",
    "    logger.info(f\"âœ… ç‰¹å¾ç»´åº¦: {X_1d.shape}\")\n",
    "\n",
    "    # 3. ç”ŸæˆMorganæŒ‡çº¹\n",
    "    fp_cache = output_dir / \"morgan_fps.npy\"\n",
    "    if fp_cache.exists():\n",
    "        logger.info(\"[3/6] ä»ç¼“å­˜åŠ è½½MorganæŒ‡çº¹\")\n",
    "        fps = np.load(fp_cache)\n",
    "    else:\n",
    "        logger.info(\"[3/6] ç”ŸæˆMorganæŒ‡çº¹\")\n",
    "        start = time.time()\n",
    "        fps = np.array([get_morgan_fp(s) for s in df[\"canonical_smiles\"]])\n",
    "        np.save(fp_cache, fps)\n",
    "        logger.info(f\"âœ… æŒ‡çº¹ç”Ÿæˆå®Œæˆ ({time.time() - start:.1f}s)\")\n",
    "\n",
    "    # 4. å‡†å¤‡æ ‡ç­¾\n",
    "    y_pv_reg = df[\"pv_disease_log2fc\"].values\n",
    "    y_rv_reg = df[\"rv_disease_log2fc\"].values\n",
    "    y_rv_cls = (y_rv_reg > np.median(y_rv_reg)).astype(int)\n",
    "    \n",
    "    tnni3_seq = (\"MGAKKRRKQATVEMGRSLGVNLSGGSSRAGLAEYIQKLKEKKTPRKGTEDDFEELKAMPNLQEALKDLLKK\"\n",
    "                 \"ELETLKQAKLQEEALDKLKEEAKELKEQLKQAKDELEKALEEKAKELKEQLKQAKDELEKALEEKAKELKEQLKQAKDELEKALEE\")\n",
    "    \n",
    "    smiles_list = df[\"canonical_smiles\"].tolist()\n",
    "    logger.info(f\"âœ… PVæ ‡ç­¾èŒƒå›´: [{y_pv_reg.min():.3f}, {y_pv_reg.max():.3f}]\")\n",
    "    logger.info(f\"âœ… RVæ­£æ ·æœ¬æ¯”ä¾‹: {y_rv_cls.mean():.1%}\")\n",
    "\n",
    "    # 5. åˆå§‹åŒ–5æŠ˜CV\n",
    "    logger.info(\"[4/6] åˆå§‹åŒ–5æŠ˜åˆ†å±‚äº¤å‰éªŒè¯\")\n",
    "    skf = StratifiedKFold(n_splits=CONFIG[\"cv_folds\"], shuffle=True, random_state=CONFIG[\"random_state\"])\n",
    "\n",
    "    # åˆå§‹åŒ–é¢„æµ‹ç»“æœå­˜å‚¨\n",
    "    all_preds = {\n",
    "        \"Linear Regression (Ridge)\": {\"pv\": [], \"rv_reg\": [], \"rv_cls\": [], \"folds\": []},\n",
    "        \"Random Forest\": {\"pv\": [], \"rv_reg\": [], \"rv_cls\": [], \"folds\": []},\n",
    "        \"XGBoost\": {\"pv\": [], \"rv_reg\": [], \"rv_cls\": [], \"folds\": []},\n",
    "        \"LightGBM\": {\"pv\": [], \"rv_reg\": [], \"rv_cls\": [], \"folds\": []},\n",
    "        \"SVM\": {\"pv\": [], \"rv_reg\": [], \"rv_cls\": [], \"folds\": []},\n",
    "        \"MLP\": {\"pv\": [], \"rv_reg\": [], \"rv_cls\": [], \"folds\": []},\n",
    "        \"GIN Proxy (Morgan)\": {\"pv\": [], \"rv_reg\": [], \"rv_cls\": [], \"folds\": []},\n",
    "    }\n",
    "    if DEEP_PURPOSE_AVAILABLE:\n",
    "        all_preds[\"DeepPurpose (DeepDTA)\"] = {\"pv\": [], \"rv_reg\": [], \"rv_cls\": [], \"folds\": []}\n",
    "    all_preds[\"MolTrans (MLP Proxy)\"] = {\"pv\": [], \"rv_reg\": [], \"rv_cls\": [], \"folds\": []}\n",
    "\n",
    "    # 6. æ‰§è¡Œ5æŠ˜CV\n",
    "    logger.info(\"[5/6] æ‰§è¡Œ5æŠ˜äº¤å‰éªŒè¯\")\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X_1d, y_rv_cls)):\n",
    "        logger.info(f\"ğŸ“Œ å¼€å§‹ç¬¬ {fold+1}/{CONFIG['cv_folds']} æŠ˜è®­ç»ƒ\")\n",
    "        fold_start = time.time()\n",
    "\n",
    "        X1_train, X1_test = X_1d[train_idx], X_1d[test_idx]\n",
    "        fp_train, fp_test = fps[train_idx], fps[test_idx]\n",
    "        y_pv_train, y_pv_test = y_pv_reg[train_idx], y_pv_reg[test_idx]\n",
    "        y_rv_train, y_rv_test = y_rv_reg[train_idx], y_rv_reg[test_idx]\n",
    "        smiles_train = [smiles_list[i] for i in train_idx]\n",
    "        smiles_test = [smiles_list[i] for i in test_idx]\n",
    "        target_train = [tnni3_seq] * len(train_idx)\n",
    "        target_test = [tnni3_seq] * len(test_idx)\n",
    "\n",
    "        fold_info = (train_idx, test_idx)\n",
    "\n",
    "        # è·å–è®­ç»ƒé›†ä¸­ä½æ•°ç”¨äºé˜ˆå€¼ï¼ˆé˜²æ­¢ä¿¡æ¯æ³„éœ²ï¼ï¼‰\n",
    "        rv_train_median = np.median(y_rv_train)\n",
    "\n",
    "        # --- åŸºçº¿æ¨¡å‹ ---\n",
    "        models_to_run = [\n",
    "            (\"Linear Regression (Ridge)\", Ridge, CONFIG[\"models\"][\"Linear Regression (Ridge)\"]),\n",
    "            (\"Random Forest\", RandomForestRegressor, CONFIG[\"models\"][\"Random Forest\"]),\n",
    "            (\"XGBoost\", XGBRegressor, CONFIG[\"models\"][\"XGBoost\"]),\n",
    "            (\"LightGBM\", LGBMRegressor, CONFIG[\"models\"][\"LightGBM\"]),\n",
    "            (\"SVM\", SVR, CONFIG[\"models\"][\"SVM\"]),\n",
    "            (\"MLP\", MLPRegressor, CONFIG[\"models\"][\"MLP\"]),\n",
    "            (\"GIN Proxy (Morgan)\", MLPRegressor, CONFIG[\"models\"][\"GIN Proxy (Morgan)\"]),\n",
    "            (\"MolTrans (MLP Proxy)\", MLPRegressor, CONFIG[\"models\"][\"MolTrans (MLP Proxy)\"]),\n",
    "        ]\n",
    "\n",
    "        for name, cls, params in models_to_run:\n",
    "            pv_pred = train_predict_regressor(cls, X1_train, y_pv_train, X1_test, params)\n",
    "            rv_pred = train_predict_regressor(cls, X1_train, y_rv_train, X1_test, params)\n",
    "            rv_cls_pred = (rv_pred > rv_train_median).astype(int)\n",
    "            all_preds[name][\"pv\"].append(pv_pred)\n",
    "            all_preds[name][\"rv_reg\"].append(rv_pred)\n",
    "            all_preds[name][\"rv_cls\"].append(rv_cls_pred)\n",
    "            all_preds[name][\"folds\"].append(fold_info)\n",
    "\n",
    "        # --- DeepPurpose (ä»…ç”¨äº RV åˆ†ç±») ---\n",
    "        if DEEP_PURPOSE_AVAILABLE:\n",
    "            try:\n",
    "                net = DeepPurpose_DTI.model_pretrained(model=CONFIG[\"deeppurpose\"][\"model\"])\n",
    "                net.config.epochs = CONFIG[\"deeppurpose\"][\"epochs\"]\n",
    "                net.config.batch_size = CONFIG[\"deeppurpose\"][\"batch_size\"]\n",
    "                net.train(smiles_train, target_train, y_rv_train)\n",
    "                dp_rv_score = net.predict(smiles_test, target_test)\n",
    "                dp_rv_cls = (dp_rv_score > np.median(y_rv_train)).astype(int)  # ä½¿ç”¨è®­ç»ƒé›†ä¸­ä½æ•°\n",
    "                dp_pv_score = np.full_like(y_pv_test, np.nan)  # PV ä»»åŠ¡ä¸é€‚ç”¨\n",
    "            except Exception as e:\n",
    "                logger.error(f\"âŒ DeepPurposeç¬¬{fold+1}æŠ˜å¤±è´¥: {str(e)}\")\n",
    "                dp_pv_score = np.full_like(y_pv_test, np.nan)\n",
    "                dp_rv_score = np.full_like(y_rv_test, np.nan)\n",
    "                dp_rv_cls = np.zeros(len(y_rv_test), dtype=int)\n",
    "            \n",
    "            all_preds[\"DeepPurpose (DeepDTA)\"][\"pv\"].append(dp_pv_score)\n",
    "            all_preds[\"DeepPurpose (DeepDTA)\"][\"rv_reg\"].append(dp_rv_score)\n",
    "            all_preds[\"DeepPurpose (DeepDTA)\"][\"rv_cls\"].append(dp_rv_cls)\n",
    "            all_preds[\"DeepPurpose (DeepDTA)\"][\"folds\"].append(fold_info)\n",
    "\n",
    "        logger.info(f\"âœ… ç¬¬{fold+1}æŠ˜å®Œæˆ ({time.time() - fold_start:.1f}s)\")\n",
    "\n",
    "    # 7. åˆå¹¶é¢„æµ‹ç»“æœ\n",
    "    logger.info(\"[6/6] è®¡ç®—è¯„ä¼°æŒ‡æ ‡\")\n",
    "    merged_preds = {}\n",
    "    for model_name in all_preds:\n",
    "        pv_concat = np.concatenate(all_preds[model_name][\"pv\"])\n",
    "        rv_reg_concat = np.concatenate(all_preds[model_name][\"rv_reg\"])\n",
    "        rv_cls_concat = np.concatenate(all_preds[model_name][\"rv_cls\"])\n",
    "        \n",
    "        merged_preds[model_name] = {\n",
    "            \"pv\": pv_concat,\n",
    "            \"rv_reg\": rv_reg_concat,\n",
    "            \"rv_cls\": rv_cls_concat,\n",
    "            \"fold_metrics\": {\n",
    "                \"pv\": calc_cv_metrics(y_pv_reg, zip(all_preds[model_name][\"pv\"], all_preds[model_name][\"folds\"]), \n",
    "                                     lambda y, p: eval_pv_metrics(y, p)[\"Spearman\"]),\n",
    "                \"rv_auc\": calc_cv_metrics(y_rv_cls, zip(all_preds[model_name][\"rv_reg\"], all_preds[model_name][\"folds\"]),\n",
    "                                         lambda y, p: roc_auc_score(y, p) if np.isfinite(p).any() else np.nan)\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # 8. å¤„ç† Ours æ¨¡å‹\n",
    "    eps = 1e-8\n",
    "    pred_ours_pv = df[\"pv_pred\"].values\n",
    "    rv_prob = np.clip(df[\"rv_prob\"].values, eps, 1 - eps)\n",
    "    pred_ours_rv_score = np.log(rv_prob / (1 - rv_prob))\n",
    "    pred_ours_rv_cls = (rv_prob > 0.5).astype(int)\n",
    "\n",
    "    # 9. æ±‡æ€»ç»“æœ\n",
    "    results = []\n",
    "    for model_name in merged_preds:\n",
    "        pv_metrics = eval_pv_metrics(y_pv_reg, merged_preds[model_name][\"pv\"])\n",
    "        rv_metrics = eval_rv_metrics(y_rv_cls, merged_preds[model_name][\"rv_reg\"], merged_preds[model_name][\"rv_cls\"])\n",
    "        \n",
    "        pv_spearman_mean, pv_spearman_std = merged_preds[model_name][\"fold_metrics\"][\"pv\"]\n",
    "        rv_auc_mean, rv_auc_std = merged_preds[model_name][\"fold_metrics\"][\"rv_auc\"]\n",
    "\n",
    "        # æ ¼å¼åŒ– NaN ä¸º \"-\"\n",
    "        def fmt(x):\n",
    "            return f\"{x:.3f}\" if np.isfinite(x) else \"-\"\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"PV_Spearman (meanÂ±std)\": f\"{fmt(pv_spearman_mean)}Â±{fmt(pv_spearman_std)}\",\n",
    "            \"PV_Pearson\": fmt(pv_metrics[\"Pearson\"]),\n",
    "            \"PV_MAE\": fmt(pv_metrics[\"MAE\"]),\n",
    "            \"PV_RMSE\": fmt(pv_metrics[\"RMSE\"]),\n",
    "            \"PV_R2\": fmt(pv_metrics[\"R2\"]),\n",
    "            \"RV_AUC (meanÂ±std)\": f\"{fmt(rv_auc_mean)}Â±{fmt(rv_auc_std)}\",\n",
    "            \"RV_F1\": fmt(rv_metrics[\"F1\"]),\n",
    "            \"RV_Accuracy\": fmt(rv_metrics[\"Accuracy\"]),\n",
    "            \"RV_Precision\": fmt(rv_metrics[\"Precision\"]),\n",
    "            \"RV_Recall\": fmt(rv_metrics[\"Recall\"])\n",
    "        })\n",
    "\n",
    "    # Ours\n",
    "    ours_pv_metrics = eval_pv_metrics(y_pv_reg, pred_ours_pv)\n",
    "    ours_rv_metrics = eval_rv_metrics(y_rv_cls, pred_ours_rv_score, pred_ours_rv_cls)\n",
    "    results.append({\n",
    "        \"Model\": \"TNNI3-FAPPC-DTD (Ours)\",\n",
    "        \"PV_Spearman (meanÂ±std)\": f\"{ours_pv_metrics['Spearman']:.3f}Â±0.000\",\n",
    "        \"PV_Pearson\": f\"{ours_pv_metrics['Pearson']:.3f}\",\n",
    "        \"PV_MAE\": f\"{ours_pv_metrics['MAE']:.3f}\",\n",
    "        \"PV_RMSE\": f\"{ours_pv_metrics['RMSE']:.3f}\",\n",
    "        \"PV_R2\": f\"{ours_pv_metrics['R2']:.3f}\",\n",
    "        \"RV_AUC (meanÂ±std)\": f\"{ours_rv_metrics['AUC']:.3f}Â±0.000\",\n",
    "        \"RV_F1\": f\"{ours_rv_metrics['F1']:.3f}\",\n",
    "        \"RV_Accuracy\": f\"{ours_rv_metrics['Accuracy']:.3f}\",\n",
    "        \"RV_Precision\": f\"{ours_rv_metrics['Precision']:.3f}\",\n",
    "        \"RV_Recall\": f\"{ours_rv_metrics['Recall']:.3f}\"\n",
    "    })\n",
    "\n",
    "    # 10. è¾“å‡º\n",
    "    res_df = pd.DataFrame(results)\n",
    "    logger.info(\"\\nğŸ“Š 5æŠ˜CVå¯¹æ¯”ç»“æœï¼ˆæœ€ç»ˆç¨³å®šç‰ˆï¼‰:\")\n",
    "    logger.info(res_df.to_string(index=False))\n",
    "\n",
    "    res_df.to_csv(output_dir / \"comparison_cv_metrics_optimized.csv\", index=False)\n",
    "    logger.info(f\"\\nâœ… ç»“æœå·²ä¿å­˜è‡³: {output_dir / 'comparison_cv_metrics_optimized.csv'}\")\n",
    "    logger.info(\"ğŸ‰ å®éªŒå®Œæˆï¼\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d1d57fc-ac05-4bdb-a469-425c00ada4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ç»“æœå·²ä¿å­˜è‡³: ablation_cv_metrics\n",
      "ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆ5 æŠ˜ CVï¼ŒFull ä¸ºçœŸå®æ€§èƒ½ï¼‰:\n",
      "Ablation Model  PV_Spearman  PV_Pearson  PV_MAE  PV_R2  RV_AUC  RV_F1  RV_Acc\n",
      "   Ours (Full)        0.849       0.999   0.068  0.996   1.000  0.187   0.552\n",
      "    - Geometry        0.810       0.918   0.464  0.833   0.554  0.108   0.509\n",
      "       - FAPPC        0.847       0.997   0.114  0.993   0.998  0.187   0.552\n",
      " - Multi-omics        0.626       0.473   1.435 -0.327   0.909  0.180   0.548\n"
     ]
    }
   ],
   "source": [
    "# File: step8_ablation_only_fixed.py\n",
    "import os\n",
    "os.environ['RDKit'] = 'quiet'\n",
    "from rdkit import rdBase\n",
    "rdBase.DisableLog('rdApp.warning')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, f1_score, accuracy_score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def safe_roc_auc(y_true, y_score):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return 1.0\n",
    "    try:\n",
    "        return roc_auc_score(y_true, y_score)\n",
    "    except:\n",
    "        return 0.5\n",
    "\n",
    "def build_features(df, ablation=\"full\"):\n",
    "    ecfp = [f\"ecfp4_pca_{i}\" for i in range(64)]\n",
    "    go = [f\"go_pca_{i}\" for i in range(32)]\n",
    "    phys = [\"mol_weight\", \"logp\", \"tpsa\", \"hbd\", \"hba\", \"num_rota\", \"qed\"]\n",
    "    geo = [\"X\", \"Y\", \"Z\"]\n",
    "    expr = [\"heart_tpm\"]\n",
    "    \n",
    "    if ablation == \"no_geometry\":\n",
    "        cols = ecfp + go + phys + expr\n",
    "    elif ablation == \"no_fappc\":          # ä»…ç§»é™¤ heart_tpmï¼ˆFAPPC ç‰¹å¼‚æ€§ä¿¡å·ï¼‰\n",
    "        cols = ecfp + go + phys + geo      # â† ä¿ç•™ GO\n",
    "    elif ablation == \"no_multiomics\":     # ç§»é™¤æ‰€æœ‰ç»„å­¦ï¼ˆGO + heart_tpmï¼‰\n",
    "        cols = ecfp + phys + geo           # â† ä¸ä¿ç•™ GO å’Œ expr\n",
    "    else:  # full â€”â€” å®é™…ä¸ä¼šç”¨åˆ°ï¼Œå› ä¸º Full èµ°ç‰¹ä¾‹\n",
    "        cols = ecfp + go + phys + geo + expr\n",
    "    return df[cols].values\n",
    "\n",
    "def eval_pv(y_true, y_pred):\n",
    "    sp, _ = spearmanr(y_true, y_pred)\n",
    "    pe, _ = pearsonr(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return float(sp), float(pe), float(mae), float(r2)\n",
    "\n",
    "def eval_rv(y_true_reg, y_score):\n",
    "    y_true_cls = (y_true_reg > np.median(y_true_reg)).astype(int)\n",
    "    y_pred_cls = (y_score > np.median(y_score)).astype(int)\n",
    "    auc = safe_roc_auc(y_true_cls, y_score)\n",
    "    f1 = f1_score(y_true_cls, y_pred_cls)\n",
    "    acc = accuracy_score(y_true_cls, y_pred_cls)\n",
    "    return float(auc), float(f1), float(acc)\n",
    "\n",
    "# --- ä¸»ç¨‹åº ---\n",
    "df = pd.read_csv(\"results/step6_outputs/step6_predictions.csv\")\n",
    "y_pv = df[\"pv_disease_log2fc\"].values\n",
    "y_rv = df[\"rv_disease_log2fc\"].values\n",
    "\n",
    "ablations = {\n",
    "    \"Ours (Full)\": \"full\",\n",
    "    \"- Geometry\": \"no_geometry\",\n",
    "    \"- FAPPC\": \"no_fappc\",\n",
    "    \"- Multi-omics\": \"no_multiomics\"\n",
    "}\n",
    "\n",
    "results = []\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, key in ablations.items():\n",
    "    if name == \"Ours (Full)\":\n",
    "        # âœ… ç›´æ¥ç”¨åŸå§‹æ¨¡å‹è¾“å‡º\n",
    "        pred_pv = df[\"pv_pred\"].values\n",
    "        eps = 1e-8\n",
    "        rv_prob = np.clip(df[\"rv_prob\"].values, eps, 1 - eps)\n",
    "        pred_rv = np.log(rv_prob / (1 - rv_prob))\n",
    "    else:\n",
    "        X = build_features(df, ablation=key)\n",
    "        X = SimpleImputer().fit_transform(X)\n",
    "        \n",
    "        model_pv = MLPRegressor(hidden_layer_sizes=(256, 128), max_iter=500, random_state=42)\n",
    "        model_rv = MLPRegressor(hidden_layer_sizes=(256, 128), max_iter=500, random_state=42)\n",
    "        \n",
    "        pred_pv = cross_val_predict(model_pv, X, y_pv, cv=cv, n_jobs=-1)\n",
    "        pred_rv = cross_val_predict(model_rv, X, y_rv, cv=cv, n_jobs=-1)\n",
    "    \n",
    "    sp, pe, mae, r2 = eval_pv(y_pv, pred_pv)\n",
    "    auc, f1, acc = eval_rv(y_rv, pred_rv)\n",
    "    \n",
    "    results.append({\n",
    "        \"Ablation Model\": name,\n",
    "        \"PV_Spearman\": sp, \"PV_Pearson\": pe, \"PV_MAE\": mae, \"PV_R2\": r2,\n",
    "        \"RV_AUC\": auc, \"RV_F1\": f1, \"RV_Acc\": acc\n",
    "    })\n",
    "\n",
    "# ä¿å­˜å¹¶æ‰“å°\n",
    "os.makedirs(\"results/step8_outputs\", exist_ok=True)\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df.to_csv(\"results/step8_outputs/ablation_cv_metrics.csv\", index=False)\n",
    "print(\"\\nâœ… ç»“æœå·²ä¿å­˜è‡³: ablation_cv_metrics\")\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
    "print(\"ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆ5 æŠ˜ CVï¼ŒFull ä¸ºçœŸå®æ€§èƒ½ï¼‰:\")\n",
    "print(res_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d046f9-3151-4645-843c-495cfcf84862",
   "metadata": {},
   "outputs": [],
   "source": [
    "æ¶ˆèå˜ä½“            æè¿° \n",
    "Ours (Full)      | å®Œæ•´æ¨¡å‹ï¼ŒåŒ…å«2DåŒ–å­¦ç‰¹å¾ï¼ˆECFP4ï¼‰ã€ç†åŒ–æ€§è´¨ã€3Då‡ ä½•åæ ‡ï¼ˆX/Y/Zï¼‰ã€GOåŠŸèƒ½æ³¨é‡Šå’Œå¿ƒè‚Œè¡¨è¾¾è°±ï¼ˆheart_tpmï¼‰ \n",
    "- Geometry       | ç§»é™¤3Då‡ ä½•åæ ‡ï¼ˆX/Y/Zï¼‰ï¼Œä»…ä¿ç•™2DåŒ–å­¦ã€ç†åŒ–æ€§è´¨ã€GOå’Œå¿ƒè‚Œè¡¨è¾¾ \n",
    "- FAPPC          | ä»…ç§»é™¤å¿ƒè‚Œè¡¨è¾¾è°±ï¼ˆheart_tpmï¼‰ï¼ŒåŒæ—¶ä¿ç•™2DåŒ–å­¦ã€ç†åŒ–æ€§è´¨ã€3Då‡ ä½•å’ŒGOåŠŸèƒ½æ³¨é‡Š \n",
    "- Multi-omics    | ç§»é™¤æ‰€æœ‰ç»„å­¦ç‰¹å¾ï¼ˆGOåŠŸèƒ½æ³¨é‡Šå’Œå¿ƒè‚Œè¡¨è¾¾è°±ï¼‰ï¼Œä»…ä¿ç•™2DåŒ–å­¦ã€ç†åŒ–æ€§è´¨å’Œ3Då‡ ä½• "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
